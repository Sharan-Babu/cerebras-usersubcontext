# cerebras-usersubcontext
Using cerebras fast LLM inference to create an effective orchestration layer that determines which parts of the context to use for the next turn in a conversation. Helps reduce input tokens cost while maintaining accuracy.
